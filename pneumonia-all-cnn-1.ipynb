{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055d2a79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T14:39:49.845165Z",
     "iopub.status.busy": "2025-07-17T14:39:49.844937Z",
     "iopub.status.idle": "2025-07-17T17:54:46.372980Z",
     "shell.execute_reply": "2025-07-17T17:54:46.372094Z"
    },
    "papermill": {
     "duration": 11696.580854,
     "end_time": "2025-07-17T17:54:46.422906",
     "exception": false,
     "start_time": "2025-07-17T14:39:49.842052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 14:39:53.205248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752763193.419566      18 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752763193.483057      18 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1752763207.335136      18 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m80134624/80134624\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94668760/94668760\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m171446536/171446536\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m171317808/171317808\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m234698864/234698864\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m234545216/234545216\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m219055592/219055592\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "\u001b[1m17225924/17225924\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m51877672/51877672\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m74836368/74836368\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
      "\u001b[1m19993432/19993432\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "\n",
      "ðŸ”§ Training model: Xception\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752763309.247978      56 service.cc:148] XLA service 0x7e0eb803c3b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752763309.248897      56 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1752763310.221013      56 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1752763314.994331      56 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 - 138s - 844ms/step - accuracy: 0.9122 - loss: 0.2109 - val_accuracy: 0.8846 - val_loss: 0.3030 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 96s - 589ms/step - accuracy: 0.9519 - loss: 0.1312 - val_accuracy: 0.8558 - val_loss: 0.3717 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9479 - loss: 0.1354 - val_accuracy: 0.8365 - val_loss: 0.4787 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 575ms/step - accuracy: 0.9567 - loss: 0.1147 - val_accuracy: 0.8846 - val_loss: 0.3386 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: VGG16\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 108s - 662ms/step - accuracy: 0.9109 - loss: 0.2543 - val_accuracy: 0.7933 - val_loss: 0.6022 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 92s - 565ms/step - accuracy: 0.9509 - loss: 0.1345 - val_accuracy: 0.8910 - val_loss: 0.3395 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 95s - 584ms/step - accuracy: 0.9576 - loss: 0.1101 - val_accuracy: 0.8446 - val_loss: 0.4768 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9526 - loss: 0.1211 - val_accuracy: 0.8942 - val_loss: 0.3437 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 92s - 563ms/step - accuracy: 0.9730 - loss: 0.0761 - val_accuracy: 0.8990 - val_loss: 0.3051 - learning_rate: 2.0000e-04\n",
      "Epoch 6/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9697 - loss: 0.0837 - val_accuracy: 0.8798 - val_loss: 0.4081 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9686 - loss: 0.0805 - val_accuracy: 0.8926 - val_loss: 0.3175 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 92s - 567ms/step - accuracy: 0.9711 - loss: 0.0753 - val_accuracy: 0.8910 - val_loss: 0.3374 - learning_rate: 4.0000e-05\n",
      "\n",
      "ðŸ”§ Training model: VGG19\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 98s - 600ms/step - accuracy: 0.9181 - loss: 0.2160 - val_accuracy: 0.8349 - val_loss: 0.4731 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9526 - loss: 0.1291 - val_accuracy: 0.8590 - val_loss: 0.4143 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 572ms/step - accuracy: 0.9601 - loss: 0.1101 - val_accuracy: 0.8878 - val_loss: 0.3340 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 578ms/step - accuracy: 0.9605 - loss: 0.0951 - val_accuracy: 0.8734 - val_loss: 0.4148 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 94s - 574ms/step - accuracy: 0.9630 - loss: 0.0993 - val_accuracy: 0.9119 - val_loss: 0.3123 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 93s - 573ms/step - accuracy: 0.9651 - loss: 0.0984 - val_accuracy: 0.8846 - val_loss: 0.3491 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 572ms/step - accuracy: 0.9653 - loss: 0.0877 - val_accuracy: 0.9006 - val_loss: 0.3109 - learning_rate: 0.0010\n",
      "Epoch 8/64\n",
      "163/163 - 93s - 572ms/step - accuracy: 0.9701 - loss: 0.0825 - val_accuracy: 0.8510 - val_loss: 0.5360 - learning_rate: 0.0010\n",
      "Epoch 9/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9695 - loss: 0.0852 - val_accuracy: 0.8446 - val_loss: 0.5390 - learning_rate: 0.0010\n",
      "Epoch 10/64\n",
      "163/163 - 92s - 567ms/step - accuracy: 0.9728 - loss: 0.0729 - val_accuracy: 0.8830 - val_loss: 0.3756 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: ResNet50\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 113s - 695ms/step - accuracy: 0.9319 - loss: 0.1756 - val_accuracy: 0.9054 - val_loss: 0.2304 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9532 - loss: 0.1230 - val_accuracy: 0.8958 - val_loss: 0.2331 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 91s - 561ms/step - accuracy: 0.9620 - loss: 0.0940 - val_accuracy: 0.8974 - val_loss: 0.2597 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 92s - 564ms/step - accuracy: 0.9785 - loss: 0.0634 - val_accuracy: 0.9006 - val_loss: 0.2537 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: ResNet50V2\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 113s - 695ms/step - accuracy: 0.9291 - loss: 0.1796 - val_accuracy: 0.8910 - val_loss: 0.2482 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 95s - 581ms/step - accuracy: 0.9561 - loss: 0.1157 - val_accuracy: 0.8894 - val_loss: 0.3442 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 95s - 581ms/step - accuracy: 0.9571 - loss: 0.1136 - val_accuracy: 0.8397 - val_loss: 0.4869 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9678 - loss: 0.0894 - val_accuracy: 0.9103 - val_loss: 0.2531 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: ResNet101\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 130s - 799ms/step - accuracy: 0.9214 - loss: 0.2069 - val_accuracy: 0.8574 - val_loss: 0.3265 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9594 - loss: 0.1042 - val_accuracy: 0.8894 - val_loss: 0.2940 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9611 - loss: 0.0966 - val_accuracy: 0.8766 - val_loss: 0.3169 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 97s - 593ms/step - accuracy: 0.9641 - loss: 0.0871 - val_accuracy: 0.8990 - val_loss: 0.2703 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 96s - 587ms/step - accuracy: 0.9695 - loss: 0.0818 - val_accuracy: 0.8878 - val_loss: 0.3177 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9705 - loss: 0.0772 - val_accuracy: 0.8974 - val_loss: 0.2499 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9732 - loss: 0.0680 - val_accuracy: 0.8814 - val_loss: 0.3746 - learning_rate: 0.0010\n",
      "Epoch 8/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9753 - loss: 0.0641 - val_accuracy: 0.8942 - val_loss: 0.3231 - learning_rate: 0.0010\n",
      "Epoch 9/64\n",
      "163/163 - 94s - 575ms/step - accuracy: 0.9814 - loss: 0.0503 - val_accuracy: 0.9006 - val_loss: 0.2847 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: ResNet101V2\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 125s - 768ms/step - accuracy: 0.9068 - loss: 0.2318 - val_accuracy: 0.8317 - val_loss: 0.4161 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 95s - 581ms/step - accuracy: 0.9457 - loss: 0.1402 - val_accuracy: 0.8333 - val_loss: 0.4791 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 95s - 581ms/step - accuracy: 0.9555 - loss: 0.1199 - val_accuracy: 0.8670 - val_loss: 0.3559 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 95s - 584ms/step - accuracy: 0.9580 - loss: 0.1158 - val_accuracy: 0.9022 - val_loss: 0.2914 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9595 - loss: 0.1078 - val_accuracy: 0.9022 - val_loss: 0.2748 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 96s - 591ms/step - accuracy: 0.9691 - loss: 0.0912 - val_accuracy: 0.8974 - val_loss: 0.3220 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 95s - 585ms/step - accuracy: 0.9624 - loss: 0.0958 - val_accuracy: 0.8958 - val_loss: 0.3313 - learning_rate: 0.0010\n",
      "Epoch 8/64\n",
      "163/163 - 95s - 585ms/step - accuracy: 0.9737 - loss: 0.0746 - val_accuracy: 0.8990 - val_loss: 0.3141 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: ResNet152\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 145s - 887ms/step - accuracy: 0.9406 - loss: 0.1513 - val_accuracy: 0.8910 - val_loss: 0.2976 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 97s - 597ms/step - accuracy: 0.9576 - loss: 0.1116 - val_accuracy: 0.9022 - val_loss: 0.2609 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 96s - 589ms/step - accuracy: 0.9578 - loss: 0.1090 - val_accuracy: 0.9038 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 95s - 580ms/step - accuracy: 0.9663 - loss: 0.0842 - val_accuracy: 0.8702 - val_loss: 0.3631 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 95s - 585ms/step - accuracy: 0.9705 - loss: 0.0796 - val_accuracy: 0.8782 - val_loss: 0.3228 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 99s - 605ms/step - accuracy: 0.9753 - loss: 0.0676 - val_accuracy: 0.9119 - val_loss: 0.2304 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "163/163 - 99s - 605ms/step - accuracy: 0.9789 - loss: 0.0584 - val_accuracy: 0.9038 - val_loss: 0.2316 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 98s - 601ms/step - accuracy: 0.9781 - loss: 0.0592 - val_accuracy: 0.9135 - val_loss: 0.2131 - learning_rate: 2.0000e-04\n",
      "Epoch 9/64\n",
      "163/163 - 97s - 596ms/step - accuracy: 0.9795 - loss: 0.0568 - val_accuracy: 0.9087 - val_loss: 0.2192 - learning_rate: 2.0000e-04\n",
      "Epoch 10/64\n",
      "163/163 - 99s - 606ms/step - accuracy: 0.9781 - loss: 0.0610 - val_accuracy: 0.9103 - val_loss: 0.2258 - learning_rate: 2.0000e-04\n",
      "Epoch 11/64\n",
      "163/163 - 98s - 604ms/step - accuracy: 0.9783 - loss: 0.0564 - val_accuracy: 0.9103 - val_loss: 0.2330 - learning_rate: 4.0000e-05\n",
      "\n",
      "ðŸ”§ Training model: ResNet152V2\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 148s - 905ms/step - accuracy: 0.9160 - loss: 0.2207 - val_accuracy: 0.7933 - val_loss: 0.5133 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 98s - 604ms/step - accuracy: 0.9507 - loss: 0.1299 - val_accuracy: 0.9087 - val_loss: 0.2616 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 98s - 599ms/step - accuracy: 0.9549 - loss: 0.1219 - val_accuracy: 0.8942 - val_loss: 0.2792 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 95s - 585ms/step - accuracy: 0.9576 - loss: 0.1061 - val_accuracy: 0.9087 - val_loss: 0.2723 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 95s - 582ms/step - accuracy: 0.9676 - loss: 0.0833 - val_accuracy: 0.9119 - val_loss: 0.2648 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: InceptionV3\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 123s - 757ms/step - accuracy: 0.8836 - loss: 0.2814 - val_accuracy: 0.8365 - val_loss: 0.3915 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9293 - loss: 0.1836 - val_accuracy: 0.8494 - val_loss: 0.3439 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 570ms/step - accuracy: 0.9333 - loss: 0.1631 - val_accuracy: 0.8574 - val_loss: 0.3755 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 93s - 572ms/step - accuracy: 0.9304 - loss: 0.1795 - val_accuracy: 0.8814 - val_loss: 0.3105 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9298 - loss: 0.1628 - val_accuracy: 0.8253 - val_loss: 0.4997 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 93s - 573ms/step - accuracy: 0.9452 - loss: 0.1462 - val_accuracy: 0.8638 - val_loss: 0.3128 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9492 - loss: 0.1387 - val_accuracy: 0.8590 - val_loss: 0.3724 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: InceptionResNetV2\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 155s - 949ms/step - accuracy: 0.8717 - loss: 0.3247 - val_accuracy: 0.8301 - val_loss: 0.3677 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 98s - 601ms/step - accuracy: 0.9201 - loss: 0.1941 - val_accuracy: 0.8558 - val_loss: 0.3471 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 98s - 601ms/step - accuracy: 0.9277 - loss: 0.1864 - val_accuracy: 0.8718 - val_loss: 0.3255 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 98s - 600ms/step - accuracy: 0.9388 - loss: 0.1543 - val_accuracy: 0.7981 - val_loss: 0.5708 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 97s - 598ms/step - accuracy: 0.9281 - loss: 0.1698 - val_accuracy: 0.8590 - val_loss: 0.3668 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 94s - 578ms/step - accuracy: 0.9482 - loss: 0.1321 - val_accuracy: 0.8926 - val_loss: 0.3012 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9505 - loss: 0.1283 - val_accuracy: 0.8926 - val_loss: 0.3036 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 94s - 578ms/step - accuracy: 0.9488 - loss: 0.1313 - val_accuracy: 0.8846 - val_loss: 0.3024 - learning_rate: 2.0000e-04\n",
      "Epoch 9/64\n",
      "163/163 - 97s - 598ms/step - accuracy: 0.9534 - loss: 0.1216 - val_accuracy: 0.8830 - val_loss: 0.3035 - learning_rate: 4.0000e-05\n",
      "\n",
      "ðŸ”§ Training model: MobileNet\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 107s - 656ms/step - accuracy: 0.9185 - loss: 0.1969 - val_accuracy: 0.7452 - val_loss: 0.7540 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9605 - loss: 0.1064 - val_accuracy: 0.9054 - val_loss: 0.2542 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 95s - 584ms/step - accuracy: 0.9651 - loss: 0.0909 - val_accuracy: 0.8910 - val_loss: 0.3203 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 95s - 585ms/step - accuracy: 0.9626 - loss: 0.0965 - val_accuracy: 0.9215 - val_loss: 0.2440 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 95s - 584ms/step - accuracy: 0.9703 - loss: 0.0723 - val_accuracy: 0.8510 - val_loss: 0.4618 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 94s - 580ms/step - accuracy: 0.9734 - loss: 0.0703 - val_accuracy: 0.8846 - val_loss: 0.3560 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 95s - 582ms/step - accuracy: 0.9758 - loss: 0.0594 - val_accuracy: 0.8606 - val_loss: 0.4335 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: MobileNetV2\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 109s - 669ms/step - accuracy: 0.9277 - loss: 0.1786 - val_accuracy: 0.8141 - val_loss: 0.5618 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 92s - 567ms/step - accuracy: 0.9521 - loss: 0.1168 - val_accuracy: 0.8574 - val_loss: 0.3966 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 569ms/step - accuracy: 0.9626 - loss: 0.0989 - val_accuracy: 0.8574 - val_loss: 0.4284 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9617 - loss: 0.0971 - val_accuracy: 0.8574 - val_loss: 0.4154 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 92s - 567ms/step - accuracy: 0.9749 - loss: 0.0725 - val_accuracy: 0.8622 - val_loss: 0.4056 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: DenseNet121\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 146s - 896ms/step - accuracy: 0.9202 - loss: 0.1890 - val_accuracy: 0.9022 - val_loss: 0.2640 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 96s - 587ms/step - accuracy: 0.9479 - loss: 0.1277 - val_accuracy: 0.8542 - val_loss: 0.3773 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 573ms/step - accuracy: 0.9561 - loss: 0.1157 - val_accuracy: 0.8798 - val_loss: 0.3320 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 577ms/step - accuracy: 0.9634 - loss: 0.0941 - val_accuracy: 0.8830 - val_loss: 0.3125 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: DenseNet169\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 165s - 1s/step - accuracy: 0.9141 - loss: 0.2178 - val_accuracy: 0.9054 - val_loss: 0.2513 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 96s - 592ms/step - accuracy: 0.9571 - loss: 0.1100 - val_accuracy: 0.8734 - val_loss: 0.3015 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 96s - 586ms/step - accuracy: 0.9663 - loss: 0.0956 - val_accuracy: 0.9167 - val_loss: 0.2296 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 96s - 587ms/step - accuracy: 0.9628 - loss: 0.0918 - val_accuracy: 0.8862 - val_loss: 0.3191 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 96s - 587ms/step - accuracy: 0.9613 - loss: 0.0949 - val_accuracy: 0.8718 - val_loss: 0.3432 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 98s - 601ms/step - accuracy: 0.9743 - loss: 0.0691 - val_accuracy: 0.8798 - val_loss: 0.3282 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: DenseNet201\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 180s - 1s/step - accuracy: 0.9045 - loss: 0.2289 - val_accuracy: 0.8253 - val_loss: 0.4366 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 96s - 591ms/step - accuracy: 0.9601 - loss: 0.1101 - val_accuracy: 0.8542 - val_loss: 0.3458 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 96s - 591ms/step - accuracy: 0.9603 - loss: 0.1033 - val_accuracy: 0.8622 - val_loss: 0.3595 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 95s - 586ms/step - accuracy: 0.9651 - loss: 0.0948 - val_accuracy: 0.8253 - val_loss: 0.5235 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 95s - 583ms/step - accuracy: 0.9714 - loss: 0.0739 - val_accuracy: 0.8606 - val_loss: 0.3888 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: NASNetMobile\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 163s - 1s/step - accuracy: 0.8972 - loss: 0.2462 - val_accuracy: 0.8077 - val_loss: 0.4384 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 93s - 570ms/step - accuracy: 0.9277 - loss: 0.1775 - val_accuracy: 0.8750 - val_loss: 0.3256 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9402 - loss: 0.1572 - val_accuracy: 0.8734 - val_loss: 0.3480 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 574ms/step - accuracy: 0.9463 - loss: 0.1413 - val_accuracy: 0.8141 - val_loss: 0.4751 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9484 - loss: 0.1242 - val_accuracy: 0.8590 - val_loss: 0.3592 - learning_rate: 2.0000e-04\n",
      "âœ… Saved summary to /kaggle/working/classification_summary.csv\n",
      "ðŸ“Š Classification Summary:\n",
      "                Model  Accuracy  Macro Precision  Macro Recall  Macro F1  \\\n",
      "0            Xception  0.884615         0.885817      0.865812  0.873887   \n",
      "1               VGG16  0.899038         0.894887      0.888462  0.891449   \n",
      "2               VGG19  0.900641         0.909660      0.878632  0.890251   \n",
      "3            ResNet50  0.905449         0.895823      0.908120  0.900806   \n",
      "4          ResNet50V2  0.891026         0.885300      0.881197  0.883150   \n",
      "5           ResNet101  0.897436         0.889323      0.893162  0.891146   \n",
      "6         ResNet101V2  0.902244         0.897092      0.893590  0.895272   \n",
      "7           ResNet152  0.913462         0.910893      0.903419  0.906871   \n",
      "8         ResNet152V2  0.908654         0.912325      0.891880  0.900262   \n",
      "9         InceptionV3  0.881410         0.873100      0.874359  0.873719   \n",
      "10  InceptionResNetV2  0.892628         0.898610      0.871368  0.881783   \n",
      "11          MobileNet  0.921474         0.929070      0.903846  0.913907   \n",
      "12        MobileNetV2  0.857372         0.894319      0.814103  0.833800   \n",
      "13        DenseNet121  0.902244         0.896517      0.894444  0.895456   \n",
      "14        DenseNet169  0.916667         0.915154      0.905983  0.910154   \n",
      "15        DenseNet201  0.854167         0.883497      0.813248  0.831469   \n",
      "16       NASNetMobile  0.875000         0.868022      0.864103  0.865966   \n",
      "\n",
      "    Weighted Precision  Weighted Recall  Weighted F1  \n",
      "0             0.884916         0.884615     0.883083  \n",
      "1             0.898609         0.899038     0.898624  \n",
      "2             0.903489         0.900641     0.898693  \n",
      "3             0.908995         0.905449     0.906171  \n",
      "4             0.890617         0.891026     0.890734  \n",
      "5             0.898112         0.897436     0.897688  \n",
      "6             0.901933         0.902244     0.902027  \n",
      "7             0.913170         0.913462     0.913065  \n",
      "8             0.909545         0.908654     0.907495  \n",
      "9             0.881629         0.881410     0.881510  \n",
      "10            0.894407         0.892628     0.890735  \n",
      "11            0.923533         0.921474     0.920288  \n",
      "12            0.875963         0.857372     0.849448  \n",
      "13            0.902031         0.902244     0.902116  \n",
      "14            0.916465         0.916667     0.916201  \n",
      "15            0.868346         0.854167     0.846931  \n",
      "16            0.874502         0.875000     0.874665  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16, VGG19, ResNet50, ResNet50V2, ResNet101, ResNet101V2, ResNet152, ResNet152V2,\n",
    "    InceptionV3, InceptionResNetV2, Xception,\n",
    "    MobileNet, MobileNetV2,\n",
    "    DenseNet121, DenseNet169, DenseNet201,\n",
    "    NASNetMobile\n",
    ")\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_preprocess\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnetv2_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as inceptionresnet_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenetv2_preprocess\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input as nasnet_preprocess\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Constants\n",
    "train_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\n",
    "test_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Data Generators\n",
    "def get_generators(preprocess_func):\n",
    "    train_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=15\n",
    "    ).flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    test_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func\n",
    "    ).flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_gen, test_gen\n",
    "\n",
    "# Build classifier head\n",
    "def build_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Models Dictionary\n",
    "models = {\n",
    "    'Xception': (Xception(weights='imagenet', include_top=False, input_shape=(224,224,3)), xception_preprocess),\n",
    "    'VGG16': (VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)), vgg_preprocess),\n",
    "    'VGG19': (VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3)), vgg19_preprocess),\n",
    "    'ResNet50': (ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3)), resnet_preprocess),\n",
    "    'ResNet50V2': (ResNet50V2(weights='imagenet', include_top=False, input_shape=(224,224,3)), resnetv2_preprocess),\n",
    "    'ResNet101': (ResNet101(weights='imagenet', include_top=False, input_shape=(224,224,3)), resnet_preprocess),\n",
    "    'ResNet101V2': (ResNet101V2(weights='imagenet', include_top=False, input_shape=(224,224,3)), resnetv2_preprocess),\n",
    "    'ResNet152': (ResNet152(weights='imagenet', include_top=False, input_shape=(224,224,3)), resnet_preprocess),\n",
    "    'ResNet152V2': (ResNet152V2(weights='imagenet', include_top=False, input_shape=(224,224,3)), resnetv2_preprocess),\n",
    "    'InceptionV3': (InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3)), inception_preprocess),\n",
    "    'InceptionResNetV2': (InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)), inceptionresnet_preprocess),\n",
    "    'MobileNet': (MobileNet(weights='imagenet', include_top=False, input_shape=(224,224,3)), mobilenet_preprocess),\n",
    "    'MobileNetV2': (MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)), mobilenetv2_preprocess),\n",
    "    'DenseNet121': (DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3)), densenet_preprocess),\n",
    "    'DenseNet169': (DenseNet169(weights='imagenet', include_top=False, input_shape=(224,224,3)), densenet_preprocess),\n",
    "    'DenseNet201': (DenseNet201(weights='imagenet', include_top=False, input_shape=(224,224,3)), densenet_preprocess),\n",
    "    'NASNetMobile': (NASNetMobile(weights='imagenet', include_top=False, input_shape=(224,224,3)), nasnet_preprocess),\n",
    "}\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2)\n",
    "\n",
    "# Result storage\n",
    "report_rows = []\n",
    "\n",
    "# Training and Evaluation Loop\n",
    "for model_name, (base_model, preprocess_func) in models.items():\n",
    "    print(f\"\\nðŸ”§ Training model: {model_name}\")\n",
    "    train_gen, test_gen = get_generators(preprocess_func)\n",
    "    model = build_model(base_model)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_gen,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_gen, verbose=0)\n",
    "    predicted_labels = (predictions > 0.5).astype(int).ravel()\n",
    "    true_labels = test_gen.classes\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(true_labels, predicted_labels, digits=6, output_dict=True)\n",
    "\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Macro Precision': report['macro avg']['precision'],\n",
    "        'Macro Recall': report['macro avg']['recall'],\n",
    "        'Macro F1': report['macro avg']['f1-score'],\n",
    "        'Weighted Precision': report['weighted avg']['precision'],\n",
    "        'Weighted Recall': report['weighted avg']['recall'],\n",
    "        'Weighted F1': report['weighted avg']['f1-score'],\n",
    "    }\n",
    "\n",
    "    report_rows.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "df_report = pd.DataFrame(report_rows)\n",
    "df_report.to_csv('/kaggle/working/classification_summary.csv', index=False)\n",
    "print(\"âœ… Saved summary to /kaggle/working/classification_summary.csv\")\n",
    "print(\"ðŸ“Š Classification Summary:\")\n",
    "print(df_report)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11705.008681,
   "end_time": "2025-07-17T17:54:50.448412",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-17T14:39:45.439731",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
