{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9974aa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-21T10:44:05.262075Z",
     "iopub.status.busy": "2025-07-21T10:44:05.261806Z",
     "iopub.status.idle": "2025-07-21T17:51:56.738370Z",
     "shell.execute_reply": "2025-07-21T17:51:56.737569Z"
    },
    "papermill": {
     "duration": 25671.531942,
     "end_time": "2025-07-21T17:51:56.790589",
     "exception": false,
     "start_time": "2025-07-21T10:44:05.258647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 10:44:08.137864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753094648.329007      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753094648.380486      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1753094793.614897      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
      "\u001b[1m27018416/27018416\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "\u001b[1m31790344/31790344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "\u001b[1m71686520/71686520\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
      "\u001b[1m115263384/115263384\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
      "\u001b[1m165234480/165234480\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "\u001b[1m258076736/258076736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "\u001b[1m24274472/24274472\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b1_notop.h5\n",
      "\u001b[1m28456008/28456008\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b2_notop.h5\n",
      "\u001b[1m35839040/35839040\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n",
      "\u001b[1m52606240/52606240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
      "\u001b[1m82420632/82420632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-m_notop.h5\n",
      "\u001b[1m214201816/214201816\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n",
      "\u001b[1m473176280/473176280\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 0us/step\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB0\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753094925.399165      57 service.cc:148] XLA service 0x7eabc4005980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753094925.400100      57 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1753094927.435082      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1753094935.948304      57 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 - 297s - 448ms/step - accuracy: 0.8938 - loss: 0.2588 - val_accuracy: 0.9087 - val_loss: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 241s - 362ms/step - accuracy: 0.9083 - loss: 0.2231 - val_accuracy: 0.8013 - val_loss: 0.6405 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 244s - 367ms/step - accuracy: 0.9106 - loss: 0.2168 - val_accuracy: 0.8606 - val_loss: 0.4024 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 243s - 366ms/step - accuracy: 0.9171 - loss: 0.2000 - val_accuracy: 0.9006 - val_loss: 0.2663 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB1\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 303s - 457ms/step - accuracy: 0.8956 - loss: 0.2536 - val_accuracy: 0.9215 - val_loss: 0.2180 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 244s - 367ms/step - accuracy: 0.9078 - loss: 0.2235 - val_accuracy: 0.8926 - val_loss: 0.2817 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 248s - 374ms/step - accuracy: 0.9107 - loss: 0.2144 - val_accuracy: 0.9167 - val_loss: 0.1980 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 243s - 365ms/step - accuracy: 0.9129 - loss: 0.2098 - val_accuracy: 0.9247 - val_loss: 0.1883 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 239s - 359ms/step - accuracy: 0.9148 - loss: 0.2073 - val_accuracy: 0.9199 - val_loss: 0.2150 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "664/664 - 241s - 363ms/step - accuracy: 0.9165 - loss: 0.2013 - val_accuracy: 0.9279 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "664/664 - 236s - 356ms/step - accuracy: 0.9194 - loss: 0.1899 - val_accuracy: 0.9279 - val_loss: 0.1986 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB2\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 302s - 456ms/step - accuracy: 0.8880 - loss: 0.2644 - val_accuracy: 0.8686 - val_loss: 0.3721 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 241s - 364ms/step - accuracy: 0.9048 - loss: 0.2321 - val_accuracy: 0.8942 - val_loss: 0.2782 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 240s - 362ms/step - accuracy: 0.9092 - loss: 0.2200 - val_accuracy: 0.8894 - val_loss: 0.2852 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 242s - 365ms/step - accuracy: 0.9128 - loss: 0.2137 - val_accuracy: 0.9054 - val_loss: 0.2502 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 239s - 361ms/step - accuracy: 0.9117 - loss: 0.2128 - val_accuracy: 0.8638 - val_loss: 0.3626 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "664/664 - 239s - 360ms/step - accuracy: 0.9139 - loss: 0.2071 - val_accuracy: 0.8766 - val_loss: 0.3156 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "664/664 - 244s - 368ms/step - accuracy: 0.9178 - loss: 0.1949 - val_accuracy: 0.8830 - val_loss: 0.3107 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB3\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 311s - 469ms/step - accuracy: 0.8917 - loss: 0.2619 - val_accuracy: 0.8830 - val_loss: 0.2768 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 241s - 363ms/step - accuracy: 0.9082 - loss: 0.2263 - val_accuracy: 0.8574 - val_loss: 0.3603 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 245s - 369ms/step - accuracy: 0.9100 - loss: 0.2155 - val_accuracy: 0.9167 - val_loss: 0.2108 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 240s - 361ms/step - accuracy: 0.9118 - loss: 0.2109 - val_accuracy: 0.8862 - val_loss: 0.2997 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 245s - 369ms/step - accuracy: 0.9150 - loss: 0.2045 - val_accuracy: 0.8654 - val_loss: 0.3543 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "664/664 - 245s - 369ms/step - accuracy: 0.9186 - loss: 0.1943 - val_accuracy: 0.8798 - val_loss: 0.3084 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB4\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 331s - 499ms/step - accuracy: 0.8960 - loss: 0.2536 - val_accuracy: 0.9183 - val_loss: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 255s - 384ms/step - accuracy: 0.9095 - loss: 0.2252 - val_accuracy: 0.8974 - val_loss: 0.2544 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 249s - 376ms/step - accuracy: 0.9130 - loss: 0.2152 - val_accuracy: 0.9311 - val_loss: 0.1771 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 247s - 373ms/step - accuracy: 0.9145 - loss: 0.2080 - val_accuracy: 0.9151 - val_loss: 0.2123 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 252s - 380ms/step - accuracy: 0.9143 - loss: 0.2054 - val_accuracy: 0.9054 - val_loss: 0.2497 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "664/664 - 249s - 375ms/step - accuracy: 0.9191 - loss: 0.1935 - val_accuracy: 0.9071 - val_loss: 0.2291 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB5\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 350s - 527ms/step - accuracy: 0.8892 - loss: 0.2660 - val_accuracy: 0.8542 - val_loss: 0.3818 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 249s - 375ms/step - accuracy: 0.9050 - loss: 0.2338 - val_accuracy: 0.9247 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 247s - 372ms/step - accuracy: 0.9099 - loss: 0.2214 - val_accuracy: 0.9038 - val_loss: 0.2364 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 246s - 370ms/step - accuracy: 0.9108 - loss: 0.2175 - val_accuracy: 0.8990 - val_loss: 0.2714 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 247s - 373ms/step - accuracy: 0.9162 - loss: 0.2037 - val_accuracy: 0.9038 - val_loss: 0.2600 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB6\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 377s - 567ms/step - accuracy: 0.8929 - loss: 0.2615 - val_accuracy: 0.8846 - val_loss: 0.2881 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 251s - 377ms/step - accuracy: 0.9050 - loss: 0.2295 - val_accuracy: 0.9167 - val_loss: 0.2050 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 250s - 376ms/step - accuracy: 0.9113 - loss: 0.2192 - val_accuracy: 0.9119 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 250s - 377ms/step - accuracy: 0.9114 - loss: 0.2127 - val_accuracy: 0.9119 - val_loss: 0.2197 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 249s - 375ms/step - accuracy: 0.9138 - loss: 0.2093 - val_accuracy: 0.9183 - val_loss: 0.2013 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "664/664 - 253s - 381ms/step - accuracy: 0.9197 - loss: 0.1986 - val_accuracy: 0.9247 - val_loss: 0.1906 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "664/664 - 250s - 376ms/step - accuracy: 0.9193 - loss: 0.1965 - val_accuracy: 0.9199 - val_loss: 0.1971 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "664/664 - 252s - 380ms/step - accuracy: 0.9186 - loss: 0.1943 - val_accuracy: 0.9263 - val_loss: 0.1800 - learning_rate: 2.0000e-04\n",
      "Epoch 9/64\n",
      "664/664 - 252s - 379ms/step - accuracy: 0.9202 - loss: 0.1928 - val_accuracy: 0.9119 - val_loss: 0.2205 - learning_rate: 2.0000e-04\n",
      "Epoch 10/64\n",
      "664/664 - 251s - 378ms/step - accuracy: 0.9210 - loss: 0.1922 - val_accuracy: 0.9167 - val_loss: 0.2220 - learning_rate: 2.0000e-04\n",
      "Epoch 11/64\n",
      "664/664 - 257s - 387ms/step - accuracy: 0.9213 - loss: 0.1907 - val_accuracy: 0.9375 - val_loss: 0.1738 - learning_rate: 4.0000e-05\n",
      "Epoch 12/64\n",
      "664/664 - 254s - 383ms/step - accuracy: 0.9213 - loss: 0.1897 - val_accuracy: 0.9343 - val_loss: 0.1746 - learning_rate: 4.0000e-05\n",
      "Epoch 13/64\n",
      "664/664 - 249s - 375ms/step - accuracy: 0.9220 - loss: 0.1887 - val_accuracy: 0.9295 - val_loss: 0.1798 - learning_rate: 4.0000e-05\n",
      "Epoch 14/64\n",
      "664/664 - 253s - 382ms/step - accuracy: 0.9234 - loss: 0.1862 - val_accuracy: 0.9279 - val_loss: 0.1818 - learning_rate: 8.0000e-06\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetB7\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 403s - 607ms/step - accuracy: 0.8925 - loss: 0.2584 - val_accuracy: 0.8862 - val_loss: 0.2615 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 254s - 383ms/step - accuracy: 0.9068 - loss: 0.2250 - val_accuracy: 0.9103 - val_loss: 0.2087 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 253s - 381ms/step - accuracy: 0.9102 - loss: 0.2171 - val_accuracy: 0.9135 - val_loss: 0.2384 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 255s - 385ms/step - accuracy: 0.9125 - loss: 0.2128 - val_accuracy: 0.9006 - val_loss: 0.2648 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 259s - 390ms/step - accuracy: 0.9178 - loss: 0.1974 - val_accuracy: 0.9151 - val_loss: 0.2055 - learning_rate: 2.0000e-04\n",
      "Epoch 6/64\n",
      "664/664 - 255s - 384ms/step - accuracy: 0.9195 - loss: 0.1946 - val_accuracy: 0.9167 - val_loss: 0.2408 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "664/664 - 256s - 386ms/step - accuracy: 0.9189 - loss: 0.1952 - val_accuracy: 0.9135 - val_loss: 0.2582 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "664/664 - 255s - 384ms/step - accuracy: 0.9216 - loss: 0.1906 - val_accuracy: 0.9183 - val_loss: 0.2313 - learning_rate: 4.0000e-05\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetV2B0\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 288s - 433ms/step - accuracy: 0.8986 - loss: 0.2475 - val_accuracy: 0.8125 - val_loss: 0.5222 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 241s - 363ms/step - accuracy: 0.9125 - loss: 0.2117 - val_accuracy: 0.8734 - val_loss: 0.3125 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 239s - 360ms/step - accuracy: 0.9146 - loss: 0.2040 - val_accuracy: 0.8478 - val_loss: 0.4464 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 240s - 361ms/step - accuracy: 0.9167 - loss: 0.1984 - val_accuracy: 0.8478 - val_loss: 0.4630 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 248s - 374ms/step - accuracy: 0.9212 - loss: 0.1871 - val_accuracy: 0.8606 - val_loss: 0.3890 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetV2B1\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 318s - 479ms/step - accuracy: 0.8938 - loss: 0.2581 - val_accuracy: 0.9087 - val_loss: 0.2414 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 253s - 381ms/step - accuracy: 0.9077 - loss: 0.2213 - val_accuracy: 0.9311 - val_loss: 0.1988 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 239s - 360ms/step - accuracy: 0.9116 - loss: 0.2147 - val_accuracy: 0.9215 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 240s - 361ms/step - accuracy: 0.9150 - loss: 0.2052 - val_accuracy: 0.9054 - val_loss: 0.2612 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 240s - 362ms/step - accuracy: 0.9168 - loss: 0.2007 - val_accuracy: 0.8670 - val_loss: 0.3445 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetV2B2\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 302s - 455ms/step - accuracy: 0.8945 - loss: 0.2553 - val_accuracy: 0.8750 - val_loss: 0.3425 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 238s - 358ms/step - accuracy: 0.9061 - loss: 0.2248 - val_accuracy: 0.8670 - val_loss: 0.3729 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 239s - 360ms/step - accuracy: 0.9103 - loss: 0.2163 - val_accuracy: 0.8654 - val_loss: 0.3300 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 238s - 358ms/step - accuracy: 0.9125 - loss: 0.2103 - val_accuracy: 0.7724 - val_loss: 0.7415 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 239s - 359ms/step - accuracy: 0.9148 - loss: 0.2074 - val_accuracy: 0.8718 - val_loss: 0.3613 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "664/664 - 237s - 357ms/step - accuracy: 0.9186 - loss: 0.1948 - val_accuracy: 0.8958 - val_loss: 0.2956 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "664/664 - 237s - 357ms/step - accuracy: 0.9191 - loss: 0.1949 - val_accuracy: 0.8686 - val_loss: 0.3755 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "664/664 - 236s - 356ms/step - accuracy: 0.9198 - loss: 0.1912 - val_accuracy: 0.8478 - val_loss: 0.4329 - learning_rate: 2.0000e-04\n",
      "Epoch 9/64\n",
      "664/664 - 236s - 356ms/step - accuracy: 0.9197 - loss: 0.1913 - val_accuracy: 0.8830 - val_loss: 0.3284 - learning_rate: 4.0000e-05\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetV2B3\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 309s - 465ms/step - accuracy: 0.8901 - loss: 0.2671 - val_accuracy: 0.9135 - val_loss: 0.2092 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 239s - 360ms/step - accuracy: 0.9052 - loss: 0.2278 - val_accuracy: 0.8766 - val_loss: 0.3099 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 237s - 357ms/step - accuracy: 0.9088 - loss: 0.2212 - val_accuracy: 0.8878 - val_loss: 0.2594 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 242s - 364ms/step - accuracy: 0.9128 - loss: 0.2092 - val_accuracy: 0.9071 - val_loss: 0.2494 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetV2S\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 335s - 504ms/step - accuracy: 0.8852 - loss: 0.2773 - val_accuracy: 0.8558 - val_loss: 0.3391 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 240s - 362ms/step - accuracy: 0.9012 - loss: 0.2399 - val_accuracy: 0.8942 - val_loss: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 243s - 365ms/step - accuracy: 0.9061 - loss: 0.2308 - val_accuracy: 0.8317 - val_loss: 0.4648 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 242s - 364ms/step - accuracy: 0.9089 - loss: 0.2211 - val_accuracy: 0.8734 - val_loss: 0.3530 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 242s - 365ms/step - accuracy: 0.9106 - loss: 0.2146 - val_accuracy: 0.8990 - val_loss: 0.2562 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetV2M\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 376s - 566ms/step - accuracy: 0.8789 - loss: 0.2871 - val_accuracy: 0.9022 - val_loss: 0.2527 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 249s - 375ms/step - accuracy: 0.8965 - loss: 0.2504 - val_accuracy: 0.8942 - val_loss: 0.2404 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 248s - 374ms/step - accuracy: 0.9024 - loss: 0.2380 - val_accuracy: 0.9119 - val_loss: 0.2175 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 248s - 373ms/step - accuracy: 0.9041 - loss: 0.2338 - val_accuracy: 0.9022 - val_loss: 0.2364 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 246s - 371ms/step - accuracy: 0.9057 - loss: 0.2292 - val_accuracy: 0.8958 - val_loss: 0.2238 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "664/664 - 246s - 371ms/step - accuracy: 0.9113 - loss: 0.2178 - val_accuracy: 0.9135 - val_loss: 0.2196 - learning_rate: 2.0000e-04\n",
      "\n",
      "ðŸ”§ Training model: EfficientNetV2L\n",
      "Found 21224 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "664/664 - 440s - 663ms/step - accuracy: 0.8810 - loss: 0.2845 - val_accuracy: 0.8702 - val_loss: 0.3242 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "664/664 - 254s - 382ms/step - accuracy: 0.8998 - loss: 0.2428 - val_accuracy: 0.8862 - val_loss: 0.3004 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "664/664 - 254s - 383ms/step - accuracy: 0.9007 - loss: 0.2394 - val_accuracy: 0.8862 - val_loss: 0.3022 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "664/664 - 251s - 378ms/step - accuracy: 0.9020 - loss: 0.2359 - val_accuracy: 0.8878 - val_loss: 0.3071 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "664/664 - 254s - 382ms/step - accuracy: 0.9108 - loss: 0.2162 - val_accuracy: 0.8846 - val_loss: 0.3051 - learning_rate: 2.0000e-04\n",
      "âœ… Saved summary to /kaggle/working/classification_summary.csv\n",
      "ðŸ“Š Classification Summary:\n",
      "               Model  Accuracy  Macro Precision  Macro Recall  Macro F1  \\\n",
      "0     EfficientNetB0  0.908654         0.908463      0.895299  0.901048   \n",
      "1     EfficientNetB1  0.924679         0.932703      0.907265  0.917421   \n",
      "2     EfficientNetB2  0.905449         0.914555      0.884188  0.895674   \n",
      "3     EfficientNetB3  0.916667         0.928155      0.895726  0.907952   \n",
      "4     EfficientNetB4  0.931090         0.926803      0.926068  0.926433   \n",
      "5     EfficientNetB5  0.924679         0.925199      0.913248  0.918564   \n",
      "6     EfficientNetB6  0.937500         0.939269      0.926923  0.932425   \n",
      "7     EfficientNetB7  0.915064         0.925622      0.894444  0.906284   \n",
      "8   EfficientNetV2B0  0.873397         0.904238      0.835470  0.854477   \n",
      "9   EfficientNetV2B1  0.931090         0.930460      0.921795  0.925773   \n",
      "10  EfficientNetV2B2  0.895833         0.913458      0.867949  0.883231   \n",
      "11  EfficientNetV2B3  0.913462         0.909490      0.905128  0.907207   \n",
      "12   EfficientNetV2S  0.894231         0.896635      0.876068  0.884396   \n",
      "13   EfficientNetV2M  0.911859         0.903629      0.910684  0.906828   \n",
      "14   EfficientNetV2L  0.886218         0.878013      0.879915  0.878940   \n",
      "\n",
      "    Weighted Precision  Weighted Recall  Weighted F1  \n",
      "0             0.908620         0.908654     0.907906  \n",
      "1             0.926854         0.924679     0.923542  \n",
      "2             0.908269         0.905449     0.903658  \n",
      "3             0.920294         0.916667     0.915033  \n",
      "4             0.931035         0.931090     0.931060  \n",
      "5             0.924763         0.924679     0.924143  \n",
      "6             0.937785         0.937500     0.937055  \n",
      "7             0.918334         0.915064     0.913455  \n",
      "8             0.887874         0.873397     0.867595  \n",
      "9             0.931012         0.931090     0.930740  \n",
      "10            0.902633         0.895833     0.892821  \n",
      "11            0.913178         0.913462     0.913230  \n",
      "12            0.894832         0.894231     0.892826  \n",
      "13            0.913210         0.911859     0.912241  \n",
      "14            0.886546         0.886218     0.886361  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import (\n",
    "    EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3,\n",
    "    EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7,\n",
    "    EfficientNetV2B0, EfficientNetV2B1, EfficientNetV2B2, EfficientNetV2B3,\n",
    "    EfficientNetV2S, EfficientNetV2M, EfficientNetV2L\n",
    ")\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as effnetv1_preprocess\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input as effnetv2_preprocess\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Training source directories\n",
    "train_sources = [\n",
    "    '/kaggle/input/chestxray-augment/train',\n",
    "    '/kaggle/input/chest-xray-pneumonia/chest_xray/train',\n",
    "    '/kaggle/input/dcgan-pneumonia/chest_xray/train'\n",
    "]\n",
    "\n",
    "# Test directory\n",
    "test_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test'\n",
    "\n",
    "# Combined training directory\n",
    "combined_train_dir = '/kaggle/working/combined_train'\n",
    "\n",
    "# Image and training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Combine all training sources into one directory\n",
    "if os.path.exists(combined_train_dir):\n",
    "    shutil.rmtree(combined_train_dir)\n",
    "\n",
    "os.makedirs(os.path.join(combined_train_dir, 'NORMAL'))\n",
    "os.makedirs(os.path.join(combined_train_dir, 'PNEUMONIA'))\n",
    "\n",
    "def copy_images(src_dir, dest_dir):\n",
    "    for label in ['NORMAL', 'PNEUMONIA']:\n",
    "        src_label_dir = os.path.join(src_dir, label)\n",
    "        dest_label_dir = os.path.join(dest_dir, label)\n",
    "        if os.path.exists(src_label_dir):\n",
    "            for fname in os.listdir(src_label_dir):\n",
    "                src_path = os.path.join(src_label_dir, fname)\n",
    "                dest_path = os.path.join(dest_label_dir, fname)\n",
    "                if os.path.isfile(src_path):\n",
    "                    shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Copy from all sources\n",
    "for src in train_sources:\n",
    "    copy_images(src, combined_train_dir)\n",
    "\n",
    "# Data Generators\n",
    "def get_generators(preprocess_func):\n",
    "    train_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=15\n",
    "    ).flow_from_directory(\n",
    "        combined_train_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    test_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func\n",
    "    ).flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_gen, test_gen\n",
    "\n",
    "# Build classifier head\n",
    "def build_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# EfficientNet Models Dictionary (Only)\n",
    "models = {\n",
    "    'EfficientNetB0': (EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB1': (EfficientNetB1(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB2': (EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB3': (EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB4': (EfficientNetB4(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB5': (EfficientNetB5(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB6': (EfficientNetB6(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB7': (EfficientNetB7(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetV2B0': (EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2B1': (EfficientNetV2B1(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2B2': (EfficientNetV2B2(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2B3': (EfficientNetV2B3(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2S': (EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2M': (EfficientNetV2M(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2L': (EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "}\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2)\n",
    "\n",
    "# Result storage\n",
    "report_rows = []\n",
    "\n",
    "# Training and Evaluation Loop\n",
    "for model_name, (base_model, preprocess_func) in models.items():\n",
    "    print(f\"\\nðŸ”§ Training model: {model_name}\")\n",
    "    train_gen, test_gen = get_generators(preprocess_func)\n",
    "    model = build_model(base_model)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_gen,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_gen, verbose=0)\n",
    "    predicted_labels = (predictions > 0.5).astype(int).ravel()\n",
    "    true_labels = test_gen.classes\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    report = classification_report(true_labels, predicted_labels, digits=6, output_dict=True)\n",
    "\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Macro Precision': report['macro avg']['precision'],\n",
    "        'Macro Recall': report['macro avg']['recall'],\n",
    "        'Macro F1': report['macro avg']['f1-score'],\n",
    "        'Weighted Precision': report['weighted avg']['precision'],\n",
    "        'Weighted Recall': report['weighted avg']['recall'],\n",
    "        'Weighted F1': report['weighted avg']['f1-score'],\n",
    "    }\n",
    "\n",
    "    report_rows.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "df_report = pd.DataFrame(report_rows)\n",
    "df_report.to_csv('/kaggle/working/classification_summary.csv', index=False)\n",
    "print(\"âœ… Saved summary to /kaggle/working/classification_summary.csv\")\n",
    "print(\"ðŸ“Š Classification Summary:\")\n",
    "print(df_report)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7893274,
     "sourceId": 12506172,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7911118,
     "sourceId": 12531994,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25680.242954,
   "end_time": "2025-07-21T17:52:01.488978",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-21T10:44:01.246024",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
