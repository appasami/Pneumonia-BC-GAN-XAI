{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40ae9df",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-17T14:38:38.177779Z",
     "iopub.status.busy": "2025-07-17T14:38:38.177500Z",
     "iopub.status.idle": "2025-07-17T17:51:06.177285Z",
     "shell.execute_reply": "2025-07-17T17:51:06.176418Z"
    },
    "papermill": {
     "duration": 11548.048955,
     "end_time": "2025-07-17T17:51:06.223437",
     "exception": false,
     "start_time": "2025-07-17T14:38:38.174482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 14:38:41.687593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752763121.918960      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752763121.988213      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1752763136.529570      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n",
      "\u001b[1m27018416/27018416\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n",
      "\u001b[1m31790344/31790344\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "\u001b[1m71686520/71686520\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
      "\u001b[1m115263384/115263384\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
      "\u001b[1m165234480/165234480\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "\u001b[1m258076736/258076736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "\u001b[1m24274472/24274472\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b1_notop.h5\n",
      "\u001b[1m28456008/28456008\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b2_notop.h5\n",
      "\u001b[1m35839040/35839040\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n",
      "\u001b[1m52606240/52606240\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
      "\u001b[1m82420632/82420632\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-m_notop.h5\n",
      "\u001b[1m214201816/214201816\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n",
      "\u001b[1m473176280/473176280\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n",
      "\n",
      "üîß Training model: EfficientNetB0\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752763251.124712      57 service.cc:148] XLA service 0x7e2594003c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752763251.125602      57 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1752763252.995363      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1752763261.509977      57 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 - 164s - 1s/step - accuracy: 0.9204 - loss: 0.1927 - val_accuracy: 0.8221 - val_loss: 0.4389 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 91s - 559ms/step - accuracy: 0.9484 - loss: 0.1271 - val_accuracy: 0.8638 - val_loss: 0.3605 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 90s - 551ms/step - accuracy: 0.9592 - loss: 0.1102 - val_accuracy: 0.8958 - val_loss: 0.2620 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 91s - 557ms/step - accuracy: 0.9605 - loss: 0.1065 - val_accuracy: 0.8285 - val_loss: 0.4543 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 90s - 555ms/step - accuracy: 0.9571 - loss: 0.1063 - val_accuracy: 0.8590 - val_loss: 0.3568 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 92s - 565ms/step - accuracy: 0.9682 - loss: 0.0822 - val_accuracy: 0.8958 - val_loss: 0.2472 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9707 - loss: 0.0810 - val_accuracy: 0.9071 - val_loss: 0.2362 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 92s - 566ms/step - accuracy: 0.9699 - loss: 0.0820 - val_accuracy: 0.8958 - val_loss: 0.2648 - learning_rate: 2.0000e-04\n",
      "Epoch 9/64\n",
      "163/163 - 94s - 577ms/step - accuracy: 0.9674 - loss: 0.0812 - val_accuracy: 0.9006 - val_loss: 0.2551 - learning_rate: 2.0000e-04\n",
      "Epoch 10/64\n",
      "163/163 - 91s - 557ms/step - accuracy: 0.9705 - loss: 0.0802 - val_accuracy: 0.9006 - val_loss: 0.2525 - learning_rate: 4.0000e-05\n",
      "\n",
      "üîß Training model: EfficientNetB1\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 140s - 860ms/step - accuracy: 0.9258 - loss: 0.1817 - val_accuracy: 0.8846 - val_loss: 0.2817 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9482 - loss: 0.1232 - val_accuracy: 0.8446 - val_loss: 0.3485 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 92s - 567ms/step - accuracy: 0.9546 - loss: 0.1121 - val_accuracy: 0.9151 - val_loss: 0.2328 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 92s - 562ms/step - accuracy: 0.9534 - loss: 0.1174 - val_accuracy: 0.9151 - val_loss: 0.2119 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 94s - 578ms/step - accuracy: 0.9567 - loss: 0.1081 - val_accuracy: 0.9343 - val_loss: 0.1917 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 94s - 574ms/step - accuracy: 0.9649 - loss: 0.0888 - val_accuracy: 0.9231 - val_loss: 0.1999 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9655 - loss: 0.0891 - val_accuracy: 0.9231 - val_loss: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 8/64\n",
      "163/163 - 93s - 571ms/step - accuracy: 0.9670 - loss: 0.0827 - val_accuracy: 0.9119 - val_loss: 0.2098 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetB2\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 144s - 881ms/step - accuracy: 0.9101 - loss: 0.2097 - val_accuracy: 0.8814 - val_loss: 0.2876 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 92s - 565ms/step - accuracy: 0.9392 - loss: 0.1416 - val_accuracy: 0.7885 - val_loss: 0.5800 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9519 - loss: 0.1229 - val_accuracy: 0.8622 - val_loss: 0.3495 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 92s - 566ms/step - accuracy: 0.9584 - loss: 0.1068 - val_accuracy: 0.8542 - val_loss: 0.3881 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetB3\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 152s - 930ms/step - accuracy: 0.9229 - loss: 0.1887 - val_accuracy: 0.9231 - val_loss: 0.1986 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 575ms/step - accuracy: 0.9496 - loss: 0.1304 - val_accuracy: 0.8862 - val_loss: 0.2895 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 94s - 574ms/step - accuracy: 0.9467 - loss: 0.1316 - val_accuracy: 0.8606 - val_loss: 0.3420 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 92s - 566ms/step - accuracy: 0.9555 - loss: 0.1062 - val_accuracy: 0.8734 - val_loss: 0.3179 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetB4\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 162s - 991ms/step - accuracy: 0.9264 - loss: 0.1801 - val_accuracy: 0.8830 - val_loss: 0.2769 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 577ms/step - accuracy: 0.9536 - loss: 0.1200 - val_accuracy: 0.8990 - val_loss: 0.2408 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 96s - 591ms/step - accuracy: 0.9530 - loss: 0.1168 - val_accuracy: 0.9071 - val_loss: 0.2087 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9569 - loss: 0.1069 - val_accuracy: 0.9135 - val_loss: 0.2109 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 93s - 573ms/step - accuracy: 0.9582 - loss: 0.1031 - val_accuracy: 0.9022 - val_loss: 0.2480 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 91s - 560ms/step - accuracy: 0.9693 - loss: 0.0871 - val_accuracy: 0.9167 - val_loss: 0.2030 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 572ms/step - accuracy: 0.9661 - loss: 0.0880 - val_accuracy: 0.9103 - val_loss: 0.2312 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 95s - 586ms/step - accuracy: 0.9678 - loss: 0.0827 - val_accuracy: 0.9135 - val_loss: 0.2123 - learning_rate: 2.0000e-04\n",
      "Epoch 9/64\n",
      "163/163 - 97s - 593ms/step - accuracy: 0.9676 - loss: 0.0829 - val_accuracy: 0.9103 - val_loss: 0.2283 - learning_rate: 4.0000e-05\n",
      "\n",
      "üîß Training model: EfficientNetB5\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 174s - 1s/step - accuracy: 0.9122 - loss: 0.2096 - val_accuracy: 0.8814 - val_loss: 0.2923 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9457 - loss: 0.1432 - val_accuracy: 0.8782 - val_loss: 0.2853 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 573ms/step - accuracy: 0.9486 - loss: 0.1326 - val_accuracy: 0.8846 - val_loss: 0.2897 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 577ms/step - accuracy: 0.9528 - loss: 0.1197 - val_accuracy: 0.9103 - val_loss: 0.2396 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 98s - 599ms/step - accuracy: 0.9540 - loss: 0.1184 - val_accuracy: 0.8926 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 96s - 588ms/step - accuracy: 0.9574 - loss: 0.1132 - val_accuracy: 0.8542 - val_loss: 0.3996 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9657 - loss: 0.0942 - val_accuracy: 0.9087 - val_loss: 0.2579 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetB6\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 192s - 1s/step - accuracy: 0.9158 - loss: 0.2007 - val_accuracy: 0.8862 - val_loss: 0.2623 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 95s - 584ms/step - accuracy: 0.9456 - loss: 0.1386 - val_accuracy: 0.8766 - val_loss: 0.3170 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 96s - 586ms/step - accuracy: 0.9507 - loss: 0.1219 - val_accuracy: 0.9215 - val_loss: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 96s - 587ms/step - accuracy: 0.9580 - loss: 0.1125 - val_accuracy: 0.9151 - val_loss: 0.2402 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9553 - loss: 0.1109 - val_accuracy: 0.9151 - val_loss: 0.2103 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 93s - 572ms/step - accuracy: 0.9607 - loss: 0.0972 - val_accuracy: 0.8990 - val_loss: 0.2415 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetB7\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 209s - 1s/step - accuracy: 0.9239 - loss: 0.1877 - val_accuracy: 0.8638 - val_loss: 0.2964 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 96s - 586ms/step - accuracy: 0.9488 - loss: 0.1329 - val_accuracy: 0.8782 - val_loss: 0.2996 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 96s - 589ms/step - accuracy: 0.9557 - loss: 0.1145 - val_accuracy: 0.8766 - val_loss: 0.3070 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 579ms/step - accuracy: 0.9647 - loss: 0.0937 - val_accuracy: 0.8878 - val_loss: 0.2443 - learning_rate: 2.0000e-04\n",
      "Epoch 5/64\n",
      "163/163 - 95s - 584ms/step - accuracy: 0.9603 - loss: 0.0957 - val_accuracy: 0.8942 - val_loss: 0.2361 - learning_rate: 2.0000e-04\n",
      "Epoch 6/64\n",
      "163/163 - 97s - 592ms/step - accuracy: 0.9655 - loss: 0.0889 - val_accuracy: 0.8910 - val_loss: 0.2570 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "163/163 - 97s - 593ms/step - accuracy: 0.9634 - loss: 0.0934 - val_accuracy: 0.8974 - val_loss: 0.2404 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 99s - 608ms/step - accuracy: 0.9682 - loss: 0.0871 - val_accuracy: 0.8958 - val_loss: 0.2512 - learning_rate: 4.0000e-05\n",
      "\n",
      "üîß Training model: EfficientNetV2B0\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 130s - 799ms/step - accuracy: 0.9248 - loss: 0.1733 - val_accuracy: 0.7292 - val_loss: 0.7812 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 91s - 558ms/step - accuracy: 0.9559 - loss: 0.1064 - val_accuracy: 0.8782 - val_loss: 0.3139 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9576 - loss: 0.1017 - val_accuracy: 0.8542 - val_loss: 0.3680 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 91s - 561ms/step - accuracy: 0.9628 - loss: 0.0960 - val_accuracy: 0.8926 - val_loss: 0.2816 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 90s - 553ms/step - accuracy: 0.9670 - loss: 0.0860 - val_accuracy: 0.8718 - val_loss: 0.3277 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 90s - 552ms/step - accuracy: 0.9680 - loss: 0.0855 - val_accuracy: 0.8942 - val_loss: 0.2820 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9722 - loss: 0.0737 - val_accuracy: 0.9103 - val_loss: 0.2586 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 92s - 565ms/step - accuracy: 0.9755 - loss: 0.0649 - val_accuracy: 0.8846 - val_loss: 0.3022 - learning_rate: 2.0000e-04\n",
      "Epoch 9/64\n",
      "163/163 - 90s - 551ms/step - accuracy: 0.9764 - loss: 0.0630 - val_accuracy: 0.8846 - val_loss: 0.3070 - learning_rate: 2.0000e-04\n",
      "Epoch 10/64\n",
      "163/163 - 90s - 555ms/step - accuracy: 0.9707 - loss: 0.0708 - val_accuracy: 0.8846 - val_loss: 0.3041 - learning_rate: 4.0000e-05\n",
      "\n",
      "üîß Training model: EfficientNetV2B1\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 137s - 839ms/step - accuracy: 0.9149 - loss: 0.1994 - val_accuracy: 0.8654 - val_loss: 0.3205 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 91s - 560ms/step - accuracy: 0.9532 - loss: 0.1229 - val_accuracy: 0.8894 - val_loss: 0.2717 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 91s - 557ms/step - accuracy: 0.9526 - loss: 0.1216 - val_accuracy: 0.8942 - val_loss: 0.2664 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 93s - 570ms/step - accuracy: 0.9582 - loss: 0.1025 - val_accuracy: 0.9022 - val_loss: 0.2339 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 91s - 556ms/step - accuracy: 0.9557 - loss: 0.1112 - val_accuracy: 0.8173 - val_loss: 0.5686 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 90s - 553ms/step - accuracy: 0.9592 - loss: 0.1020 - val_accuracy: 0.8990 - val_loss: 0.2294 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 90s - 551ms/step - accuracy: 0.9630 - loss: 0.0903 - val_accuracy: 0.8558 - val_loss: 0.4243 - learning_rate: 0.0010\n",
      "Epoch 8/64\n",
      "163/163 - 90s - 554ms/step - accuracy: 0.9641 - loss: 0.0929 - val_accuracy: 0.8974 - val_loss: 0.2517 - learning_rate: 0.0010\n",
      "Epoch 9/64\n",
      "163/163 - 90s - 554ms/step - accuracy: 0.9672 - loss: 0.0820 - val_accuracy: 0.8846 - val_loss: 0.3022 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetV2B2\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 142s - 869ms/step - accuracy: 0.9187 - loss: 0.1861 - val_accuracy: 0.8734 - val_loss: 0.3183 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 574ms/step - accuracy: 0.9513 - loss: 0.1262 - val_accuracy: 0.8974 - val_loss: 0.2534 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 93s - 570ms/step - accuracy: 0.9542 - loss: 0.1163 - val_accuracy: 0.7981 - val_loss: 0.7269 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 580ms/step - accuracy: 0.9595 - loss: 0.1068 - val_accuracy: 0.8558 - val_loss: 0.3399 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 94s - 577ms/step - accuracy: 0.9628 - loss: 0.0921 - val_accuracy: 0.8750 - val_loss: 0.2978 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetV2B3\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 153s - 941ms/step - accuracy: 0.9224 - loss: 0.1862 - val_accuracy: 0.8606 - val_loss: 0.3358 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 92s - 566ms/step - accuracy: 0.9490 - loss: 0.1287 - val_accuracy: 0.8942 - val_loss: 0.2549 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 92s - 563ms/step - accuracy: 0.9534 - loss: 0.1231 - val_accuracy: 0.8942 - val_loss: 0.2420 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 92s - 566ms/step - accuracy: 0.9580 - loss: 0.1145 - val_accuracy: 0.9006 - val_loss: 0.2165 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 91s - 555ms/step - accuracy: 0.9599 - loss: 0.1082 - val_accuracy: 0.9119 - val_loss: 0.2221 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 91s - 556ms/step - accuracy: 0.9561 - loss: 0.1136 - val_accuracy: 0.9006 - val_loss: 0.2194 - learning_rate: 0.0010\n",
      "Epoch 7/64\n",
      "163/163 - 90s - 555ms/step - accuracy: 0.9659 - loss: 0.0952 - val_accuracy: 0.9022 - val_loss: 0.2404 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetV2S\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 164s - 1s/step - accuracy: 0.9110 - loss: 0.2159 - val_accuracy: 0.8750 - val_loss: 0.2721 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 92s - 562ms/step - accuracy: 0.9358 - loss: 0.1560 - val_accuracy: 0.8862 - val_loss: 0.2589 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 91s - 560ms/step - accuracy: 0.9429 - loss: 0.1404 - val_accuracy: 0.8622 - val_loss: 0.3198 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 574ms/step - accuracy: 0.9456 - loss: 0.1374 - val_accuracy: 0.7692 - val_loss: 0.6536 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 94s - 578ms/step - accuracy: 0.9469 - loss: 0.1246 - val_accuracy: 0.8814 - val_loss: 0.2778 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetV2M\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 197s - 1s/step - accuracy: 0.9080 - loss: 0.2164 - val_accuracy: 0.8734 - val_loss: 0.2904 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 94s - 574ms/step - accuracy: 0.9358 - loss: 0.1600 - val_accuracy: 0.8974 - val_loss: 0.2579 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 92s - 567ms/step - accuracy: 0.9417 - loss: 0.1499 - val_accuracy: 0.8974 - val_loss: 0.2411 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 93s - 569ms/step - accuracy: 0.9467 - loss: 0.1399 - val_accuracy: 0.9006 - val_loss: 0.2464 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 93s - 570ms/step - accuracy: 0.9406 - loss: 0.1418 - val_accuracy: 0.8766 - val_loss: 0.2685 - learning_rate: 0.0010\n",
      "Epoch 6/64\n",
      "163/163 - 93s - 568ms/step - accuracy: 0.9490 - loss: 0.1267 - val_accuracy: 0.9054 - val_loss: 0.2440 - learning_rate: 2.0000e-04\n",
      "\n",
      "üîß Training model: EfficientNetV2L\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "163/163 - 241s - 1s/step - accuracy: 0.9020 - loss: 0.2263 - val_accuracy: 0.8462 - val_loss: 0.3538 - learning_rate: 0.0010\n",
      "Epoch 2/64\n",
      "163/163 - 100s - 612ms/step - accuracy: 0.9344 - loss: 0.1569 - val_accuracy: 0.8814 - val_loss: 0.3141 - learning_rate: 0.0010\n",
      "Epoch 3/64\n",
      "163/163 - 97s - 593ms/step - accuracy: 0.9390 - loss: 0.1545 - val_accuracy: 0.8670 - val_loss: 0.3310 - learning_rate: 0.0010\n",
      "Epoch 4/64\n",
      "163/163 - 94s - 576ms/step - accuracy: 0.9373 - loss: 0.1523 - val_accuracy: 0.8510 - val_loss: 0.3799 - learning_rate: 0.0010\n",
      "Epoch 5/64\n",
      "163/163 - 95s - 581ms/step - accuracy: 0.9475 - loss: 0.1337 - val_accuracy: 0.8862 - val_loss: 0.3027 - learning_rate: 2.0000e-04\n",
      "Epoch 6/64\n",
      "163/163 - 93s - 572ms/step - accuracy: 0.9498 - loss: 0.1257 - val_accuracy: 0.8782 - val_loss: 0.3088 - learning_rate: 2.0000e-04\n",
      "Epoch 7/64\n",
      "163/163 - 94s - 577ms/step - accuracy: 0.9532 - loss: 0.1205 - val_accuracy: 0.8718 - val_loss: 0.3085 - learning_rate: 2.0000e-04\n",
      "Epoch 8/64\n",
      "163/163 - 94s - 577ms/step - accuracy: 0.9498 - loss: 0.1240 - val_accuracy: 0.8798 - val_loss: 0.3078 - learning_rate: 4.0000e-05\n",
      "‚úÖ Saved summary to /kaggle/working/classification_summary.csv\n",
      "üìä Classification Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Weighted Precision</th>\n",
       "      <th>Weighted Recall</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EfficientNetB0</td>\n",
       "      <td>0.907051</td>\n",
       "      <td>0.899900</td>\n",
       "      <td>0.902564</td>\n",
       "      <td>0.901188</td>\n",
       "      <td>0.907438</td>\n",
       "      <td>0.907051</td>\n",
       "      <td>0.907206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EfficientNetB1</td>\n",
       "      <td>0.934295</td>\n",
       "      <td>0.928506</td>\n",
       "      <td>0.932051</td>\n",
       "      <td>0.930208</td>\n",
       "      <td>0.934691</td>\n",
       "      <td>0.934295</td>\n",
       "      <td>0.934430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EfficientNetB2</td>\n",
       "      <td>0.881410</td>\n",
       "      <td>0.889906</td>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.868429</td>\n",
       "      <td>0.884290</td>\n",
       "      <td>0.881410</td>\n",
       "      <td>0.878761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EfficientNetB3</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.917369</td>\n",
       "      <td>0.922844</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.922798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EfficientNetB4</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.915154</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.910154</td>\n",
       "      <td>0.916465</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EfficientNetB5</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.901510</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.905355</td>\n",
       "      <td>0.912170</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.910740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EfficientNetB6</td>\n",
       "      <td>0.921474</td>\n",
       "      <td>0.918480</td>\n",
       "      <td>0.913248</td>\n",
       "      <td>0.915724</td>\n",
       "      <td>0.921228</td>\n",
       "      <td>0.921474</td>\n",
       "      <td>0.921227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EfficientNetB7</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.897663</td>\n",
       "      <td>0.875214</td>\n",
       "      <td>0.884158</td>\n",
       "      <td>0.895138</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.892698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EfficientNetV2B0</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.926607</td>\n",
       "      <td>0.885470</td>\n",
       "      <td>0.899982</td>\n",
       "      <td>0.916153</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.907996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EfficientNetV2B1</td>\n",
       "      <td>0.899038</td>\n",
       "      <td>0.890189</td>\n",
       "      <td>0.897009</td>\n",
       "      <td>0.893276</td>\n",
       "      <td>0.900491</td>\n",
       "      <td>0.899038</td>\n",
       "      <td>0.899476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EfficientNetV2B2</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.887406</td>\n",
       "      <td>0.900855</td>\n",
       "      <td>0.892631</td>\n",
       "      <td>0.901894</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.898309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EfficientNetV2B3</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.894017</td>\n",
       "      <td>0.894017</td>\n",
       "      <td>0.894017</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.900641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EfficientNetV2S</td>\n",
       "      <td>0.886218</td>\n",
       "      <td>0.877312</td>\n",
       "      <td>0.881624</td>\n",
       "      <td>0.879338</td>\n",
       "      <td>0.887096</td>\n",
       "      <td>0.886218</td>\n",
       "      <td>0.886541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EfficientNetV2M</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>0.882906</td>\n",
       "      <td>0.888789</td>\n",
       "      <td>0.897263</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.896541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EfficientNetV2L</td>\n",
       "      <td>0.886218</td>\n",
       "      <td>0.880986</td>\n",
       "      <td>0.874786</td>\n",
       "      <td>0.877664</td>\n",
       "      <td>0.885677</td>\n",
       "      <td>0.886218</td>\n",
       "      <td>0.885751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy  Macro Precision  Macro Recall  Macro F1  \\\n",
       "0     EfficientNetB0  0.907051         0.899900      0.902564  0.901188   \n",
       "1     EfficientNetB1  0.934295         0.928506      0.932051  0.930208   \n",
       "2     EfficientNetB2  0.881410         0.889906      0.856410  0.868429   \n",
       "3     EfficientNetB3  0.923077         0.920576      0.914530  0.917369   \n",
       "4     EfficientNetB4  0.916667         0.915154      0.905983  0.910154   \n",
       "5     EfficientNetB5  0.910256         0.901510      0.910256  0.905355   \n",
       "6     EfficientNetB6  0.921474         0.918480      0.913248  0.915724   \n",
       "7     EfficientNetB7  0.894231         0.897663      0.875214  0.884158   \n",
       "8   EfficientNetV2B0  0.910256         0.926607      0.885470  0.899982   \n",
       "9   EfficientNetV2B1  0.899038         0.890189      0.897009  0.893276   \n",
       "10  EfficientNetV2B2  0.897436         0.887406      0.900855  0.892631   \n",
       "11  EfficientNetV2B3  0.900641         0.894017      0.894017  0.894017   \n",
       "12   EfficientNetV2S  0.886218         0.877312      0.881624  0.879338   \n",
       "13   EfficientNetV2M  0.897436         0.896514      0.882906  0.888789   \n",
       "14   EfficientNetV2L  0.886218         0.880986      0.874786  0.877664   \n",
       "\n",
       "    Weighted Precision  Weighted Recall  Weighted F1  \n",
       "0             0.907438         0.907051     0.907206  \n",
       "1             0.934691         0.934295     0.934430  \n",
       "2             0.884290         0.881410     0.878761  \n",
       "3             0.922844         0.923077     0.922798  \n",
       "4             0.916465         0.916667     0.916201  \n",
       "5             0.912170         0.910256     0.910740  \n",
       "6             0.921228         0.921474     0.921227  \n",
       "7             0.895138         0.894231     0.892698  \n",
       "8             0.916153         0.910256     0.907996  \n",
       "9             0.900491         0.899038     0.899476  \n",
       "10            0.901894         0.897436     0.898309  \n",
       "11            0.900641         0.900641     0.900641  \n",
       "12            0.887096         0.886218     0.886541  \n",
       "13            0.897263         0.897436     0.896541  \n",
       "14            0.885677         0.886218     0.885751  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import (\n",
    "    EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3,\n",
    "    EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7,\n",
    "    EfficientNetV2B0, EfficientNetV2B1, EfficientNetV2B2, EfficientNetV2B3,\n",
    "    EfficientNetV2S, EfficientNetV2M, EfficientNetV2L\n",
    ")\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as effnetv1_preprocess\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input as effnetv2_preprocess\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import display\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Constants\n",
    "train_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\n",
    "test_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Data Generators\n",
    "def get_generators(preprocess_func):\n",
    "    train_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=15\n",
    "    ).flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    test_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_func\n",
    "    ).flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_gen, test_gen\n",
    "\n",
    "# Build classifier\n",
    "def build_model(base_model):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# EfficientNet Models\n",
    "models = {\n",
    "    'EfficientNetB0': (EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB1': (EfficientNetB1(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB2': (EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB3': (EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB4': (EfficientNetB4(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB5': (EfficientNetB5(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB6': (EfficientNetB6(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetB7': (EfficientNetB7(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv1_preprocess),\n",
    "    'EfficientNetV2B0': (EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2B1': (EfficientNetV2B1(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2B2': (EfficientNetV2B2(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2B3': (EfficientNetV2B3(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2S': (EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2M': (EfficientNetV2M(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "    'EfficientNetV2L': (EfficientNetV2L(weights='imagenet', include_top=False, input_shape=(224,224,3)), effnetv2_preprocess),\n",
    "}\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.2)\n",
    "\n",
    "# Result storage\n",
    "report_rows = []\n",
    "\n",
    "# Training and Evaluation Loop\n",
    "for model_name, (base_model, preprocess_func) in models.items():\n",
    "    print(f\"\\nüîß Training model: {model_name}\")\n",
    "    train_gen, test_gen = get_generators(preprocess_func)\n",
    "    model = build_model(base_model)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_gen,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(test_gen, verbose=0)\n",
    "    predicted_labels = (predictions > 0.5).astype(int).ravel()\n",
    "    true_labels = test_gen.classes\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    report = classification_report(true_labels, predicted_labels, digits=6, output_dict=True)\n",
    "\n",
    "    row = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Macro Precision': report['macro avg']['precision'],\n",
    "        'Macro Recall': report['macro avg']['recall'],\n",
    "        'Macro F1': report['macro avg']['f1-score'],\n",
    "        'Weighted Precision': report['weighted avg']['precision'],\n",
    "        'Weighted Recall': report['weighted avg']['recall'],\n",
    "        'Weighted F1': report['weighted avg']['f1-score'],\n",
    "    }\n",
    "    report_rows.append(row)\n",
    "\n",
    "# Save and display CSV\n",
    "df_report = pd.DataFrame(report_rows)\n",
    "csv_path = '/kaggle/working/classification_summary.csv'\n",
    "df_report.to_csv(csv_path, index=False)\n",
    "print(f\"‚úÖ Saved summary to {csv_path}\")\n",
    "print(\"üìä Classification Summary:\")\n",
    "display(df_report)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11557.004005,
   "end_time": "2025-07-17T17:51:10.640224",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-17T14:38:33.636219",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
